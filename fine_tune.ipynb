{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 13 18:15:40 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64       Driver Version: 440.64       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN RTX           Off  | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 42%   60C    P2    78W / 280W |   3954MiB / 24219MiB |      3%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 41%   38C    P2    53W / 280W |   5586MiB / 24220MiB |     25%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN RTX           Off  | 00000000:82:00.0 Off |                  N/A |\r\n",
      "| 41%   32C    P8     6W / 280W |   3081MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  TITAN RTX           Off  | 00000000:83:00.0 Off |                  N/A |\r\n",
      "| 40%   49C    P2    83W / 280W |   1359MiB / 24220MiB |     24%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(2, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(14, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(27, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Sequential(\n",
       "      (0): Conv2d(64, 26, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(26, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(27, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Sequential(\n",
       "      (0): Conv2d(128, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Sequential(\n",
       "      (0): Conv2d(128, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(36, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(37, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Sequential(\n",
       "      (0): Conv2d(256, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(37, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(39, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Sequential(\n",
       "      (0): Conv2d(256, 33, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(33, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(34, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Sequential(\n",
       "      (0): Conv2d(256, 70, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(70, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(76, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Sequential(\n",
       "      (0): Conv2d(512, 158, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(158, 211, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(211, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Sequential(\n",
       "      (0): Conv2d(512, 150, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(150, 153, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(153, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Sequential(\n",
       "      (0): Conv2d(512, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(136, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(124, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Sequential(\n",
       "      (0): Conv2d(512, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(116, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(118, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Sequential(\n",
       "      (0): Conv2d(512, 135, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): Conv2d(135, 134, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (2): Conv2d(134, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PATH = 'CIFAR10_VGG16_compressed.pth'\n",
    "PATH = 'CIFAR10_VGG16_compressed_v2.pth'\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#также будем использовать аугментацию: рандомные повороты на 7 градусов и отражение относительно вертикали.\n",
    "\n",
    "#преобразование трейна\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(7),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "#тест не меняем\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train = torchvision.datasets.CIFAR10('./', download=True, train=True, transform=train_tf)\n",
    "test = torchvision.datasets.CIFAR10('./', download=True, train=False, transform=test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size = 64, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size = 256, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#В качестве лоса возмем кросс-энтропию. Оптимизатор - Адам\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "#добавим уменьшение лернинг рейта, если выходим на плато. Это решение будем принимать по валидационной выборке.\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=7, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 0.0\n",
    "len_test = 0.0\n",
    "\n",
    "for _, (inputs, targets) in enumerate(testloader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    outputs = model(inputs)\n",
    "    accuracy_add = (outputs.argmax(dim=1) == targets).float().sum().data.cpu()\n",
    "    test_acc += accuracy_add\n",
    "    len_test += len(targets)\n",
    "    \n",
    "test_acc = test_acc / len_test\n",
    "test_acc = np.round(test_acc.numpy(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test after compression: 0.1496\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test after compression:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    len_train = 0.0\n",
    "    len_test = 0.0\n",
    "    \n",
    "    loss_train = 0.0\n",
    "  \n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss_val = loss(outputs, targets)\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        accuracy_add = (outputs.argmax(dim=1) == targets).float().sum().data.cpu()\n",
    "        train_acc += accuracy_add\n",
    "        len_train += len(targets)\n",
    "        loss_train += len(targets) * loss_val.item()\n",
    "        running_loss += loss_val.item()\n",
    "        \n",
    "    for _, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        accuracy_add = (outputs.argmax(dim=1) == targets).float().sum().data.cpu()\n",
    "        test_acc += accuracy_add\n",
    "        len_test += len(targets)\n",
    "\n",
    "        \n",
    "    lr_scheduler.step(running_loss)\n",
    "\n",
    "    return train_acc / len_train, test_acc / len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0    acc_train: 0.6794    test_acc: 0.6949\n",
      "Epoch: 1    acc_train: 0.7293    test_acc: 0.739\n",
      "Epoch: 2    acc_train: 0.7485    test_acc: 0.7412\n",
      "Epoch: 3    acc_train: 0.7663    test_acc: 0.7819\n",
      "Epoch: 4    acc_train: 0.7629    test_acc: 0.7681\n",
      "Epoch: 5    acc_train: 0.7714    test_acc: 0.7728\n",
      "Epoch: 6    acc_train: 0.7913    test_acc: 0.7945\n",
      "Epoch: 7    acc_train: 0.7994    test_acc: 0.7856\n",
      "Epoch: 8    acc_train: 0.8006    test_acc: 0.7933\n",
      "Epoch: 9    acc_train: 0.7936    test_acc: 0.7714\n",
      "Epoch: 10    acc_train: 0.8049    test_acc: 0.8045\n"
     ]
    }
   ],
   "source": [
    "accuracy_history_test = []\n",
    "accuracy_history_train = []\n",
    "\n",
    "for epoch in range(0, 19):\n",
    "    train_acc, test_acc = train(epoch)\n",
    "    accuracy_history_test.append(test_acc)\n",
    "    accuracy_history_train.append(train_acc)\n",
    "    acc_train = np.round(train_acc.numpy(), 4)\n",
    "    acc_test = np.round(test_acc.numpy(), 4)\n",
    "    print('Epoch:', epoch, '   acc_train:', acc_train, '   test_acc:', acc_test)\n",
    "    if acc_test > 0.8: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model): \n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params in model after compression: 125549659\n",
      "Num params in model before compression: 138357544\n",
      "Ratio: 1.1020144945196546\n"
     ]
    }
   ],
   "source": [
    "print('Num params in model after compression:', count_parameters(model))\n",
    "print('Num params in model before compression:', 138357544)\n",
    "print('Ratio:', 138357544 / count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
